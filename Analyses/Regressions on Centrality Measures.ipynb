{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import rcParams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle_files(folder_path):\n",
    "    pickle_dict = {}\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.pkl'):\n",
    "            year = filename[-8:-4]\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            with open(file_path, 'rb') as file:\n",
    "                data = pickle.load(file)\n",
    "            pickle_dict[year] = data\n",
    "    return pickle_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(folder_path):\n",
    "    graphs_by_year = load_pickle_files(folder_path)\n",
    "    # Initialize an empty list to store the results\n",
    "    results = []\n",
    "\n",
    "    # Iterate through each graph in the dictionary\n",
    "    for year, graph in graphs_by_year.items():\n",
    "        # Compute centrality measures\n",
    "        degree_centrality = nx.degree_centrality(graph)\n",
    "        closeness_centrality = nx.closeness_centrality(graph)\n",
    "        betweenness_centrality = nx.betweenness_centrality(graph)\n",
    "        eigenvector_centrality = nx.eigenvector_centrality_numpy(graph)\n",
    "        \n",
    "        # Store the results for each node\n",
    "        for node in graph.nodes():\n",
    "            results.append({\n",
    "                'Year': year,\n",
    "                'Node': node,\n",
    "                'Degree Centrality': degree_centrality[node],\n",
    "                'Closeness Centrality': closeness_centrality[node],\n",
    "                'Betweenness Centrality': betweenness_centrality[node],\n",
    "                'Eigenvector Centrality': eigenvector_centrality[node]\n",
    "            })\n",
    "\n",
    "    # Convert the results list to a DataFrame\n",
    "    centrality_df = pd.DataFrame(results)\n",
    "\n",
    "    # Display the DataFrame\n",
    "    print(centrality_df)\n",
    "\n",
    "    return centrality_df\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Year     Node  Degree Centrality  Closeness Centrality  \\\n",
      "0      2010  1417398           0.008818              0.154232   \n",
      "1      2010       20           0.000827              0.130905   \n",
      "2      2010  1130464           0.003582              0.149992   \n",
      "3      2010    12400           0.000276              0.127890   \n",
      "4      2010   354707           0.002204              0.109409   \n",
      "...     ...      ...                ...                   ...   \n",
      "56653  2023  1906425           0.000218              0.000000   \n",
      "56654  2023  1611282           0.000218              0.000000   \n",
      "56655  2023  1972912           0.000218              0.000000   \n",
      "56656  2023  1929288           0.000218              0.000000   \n",
      "56657  2023  1945154           0.000218              0.000000   \n",
      "\n",
      "       Betweenness Centrality  Eigenvector Centrality  \n",
      "0                    0.018056            9.095141e-05  \n",
      "1                    0.000000            1.769807e-05  \n",
      "2                    0.004272            1.306589e-04  \n",
      "3                    0.000000            1.904934e-05  \n",
      "4                    0.002200            9.012160e-07  \n",
      "...                       ...                     ...  \n",
      "56653                0.000000            1.286575e-18  \n",
      "56654                0.000000            2.908429e-19  \n",
      "56655                0.000000            8.948279e-19  \n",
      "56656                0.000000           -1.391756e-19  \n",
      "56657                0.000000            2.524121e-18  \n",
      "\n",
      "[56658 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "folder_path = '../Pickle Graphs/'\n",
    "centrality_df = main(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       year      cik  Degree Centrality  Closeness Centrality  \\\n",
      "0      2010  1417398           0.008818              0.154232   \n",
      "1      2010       20           0.000827              0.130905   \n",
      "2      2010  1130464           0.003582              0.149992   \n",
      "3      2010    12400           0.000276              0.127890   \n",
      "4      2010   354707           0.002204              0.109409   \n",
      "...     ...      ...                ...                   ...   \n",
      "56653  2023  1906425           0.000218              0.000000   \n",
      "56654  2023  1611282           0.000218              0.000000   \n",
      "56655  2023  1972912           0.000218              0.000000   \n",
      "56656  2023  1929288           0.000218              0.000000   \n",
      "56657  2023  1945154           0.000218              0.000000   \n",
      "\n",
      "       Betweenness Centrality  Eigenvector Centrality  \n",
      "0                    0.018056            9.095141e-05  \n",
      "1                    0.000000            1.769807e-05  \n",
      "2                    0.004272            1.306589e-04  \n",
      "3                    0.000000            1.904934e-05  \n",
      "4                    0.002200            9.012160e-07  \n",
      "...                       ...                     ...  \n",
      "56653                0.000000            1.286575e-18  \n",
      "56654                0.000000            2.908429e-19  \n",
      "56655                0.000000            8.948279e-19  \n",
      "56656                0.000000           -1.391756e-19  \n",
      "56657                0.000000            2.524121e-18  \n",
      "\n",
      "[56658 rows x 6 columns]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You are trying to merge on float64 and object columns for key 'year'. If you wish to proceed you should use pd.concat",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(centrality_df)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Merge the financial data with the centrality data\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m merged_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinancial_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcentrality_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcik\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43myear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m merged_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(merged_df, sector_codes, on\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcik\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\feldberg.dartmouth\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:170\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _cross_merge(\n\u001b[0;32m    156\u001b[0m         left_df,\n\u001b[0;32m    157\u001b[0m         right_df,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    167\u001b[0m         copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    168\u001b[0m     )\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 170\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_MergeOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result(copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32mc:\\Users\\feldberg.dartmouth\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:807\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[0;32m    803\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_tolerance(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_join_keys)\n\u001b[0;32m    805\u001b[0m \u001b[38;5;66;03m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[0;32m    806\u001b[0m \u001b[38;5;66;03m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[1;32m--> 807\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_coerce_merge_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    809\u001b[0m \u001b[38;5;66;03m# If argument passed to validate,\u001b[39;00m\n\u001b[0;32m    810\u001b[0m \u001b[38;5;66;03m# check if columns specified as unique\u001b[39;00m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;66;03m# are in fact unique.\u001b[39;00m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\feldberg.dartmouth\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1508\u001b[0m, in \u001b[0;36m_MergeOperation._maybe_coerce_merge_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1502\u001b[0m     \u001b[38;5;66;03m# unless we are merging non-string-like with string-like\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[0;32m   1504\u001b[0m         inferred_left \u001b[38;5;129;01min\u001b[39;00m string_types \u001b[38;5;129;01mand\u001b[39;00m inferred_right \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m string_types\n\u001b[0;32m   1505\u001b[0m     ) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   1506\u001b[0m         inferred_right \u001b[38;5;129;01min\u001b[39;00m string_types \u001b[38;5;129;01mand\u001b[39;00m inferred_left \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m string_types\n\u001b[0;32m   1507\u001b[0m     ):\n\u001b[1;32m-> 1508\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;66;03m# datetimelikes must match exactly\u001b[39;00m\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m needs_i8_conversion(lk\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m needs_i8_conversion(rk\u001b[38;5;241m.\u001b[39mdtype):\n",
      "\u001b[1;31mValueError\u001b[0m: You are trying to merge on float64 and object columns for key 'year'. If you wish to proceed you should use pd.concat"
     ]
    }
   ],
   "source": [
    "centrality_df.rename(columns={'Node':'cik', 'Year':'year'}, inplace=True)\n",
    "centrality_df['year']=centrality_df['year'].astype(int)\n",
    "\n",
    "# Load in Financial Data\n",
    "financial_data = pd.read_csv(\"../Financial Data/CompustatCRSP_Annual.csv\")\n",
    "financial_data.rename(columns={\"fyear\" : \"year\"}, inplace=True)\n",
    "financial_data = financial_data[['year','bkvlps', 'epspx', 'cik']]\n",
    "\n",
    "# Load in Sector Codes\n",
    "sector_codes = pd.read_csv(\"../Financial Data/NAICS.csv\", dtype={'naics':str})\n",
    "sector_codes = sector_codes[['cik','naics']]\n",
    "sector_codes = sector_codes.drop_duplicates(subset=['cik'])\n",
    "# Create new columns for sector, subsector, and industry group\n",
    "sector_codes['sector'] = sector_codes['naics'].str[:2]\n",
    "sector_codes['subsector'] = sector_codes['naics'].str[:3]\n",
    "sector_codes['industry_group'] = sector_codes['naics'].str[:4]\n",
    "sector_codes.drop(['naics'],axis=1, inplace=True)\n",
    "centrality_df['year']=centrality_df['year'].astype(int)\n",
    "\n",
    "print(centrality_df)\n",
    "# Merge the financial data with the centrality data\n",
    "merged_df = pd.merge(financial_data, centrality_df, on=['cik', 'year'])\n",
    "merged_df = pd.merge(merged_df, sector_codes, on=['cik'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
